{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in d:\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda3\\lib\\site-packages (from Keras) (1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in d:\\anaconda3\\lib\\site-packages (from Keras) (1.0.6)\n",
      "Requirement already satisfied: scipy>=0.14 in d:\\anaconda3\\lib\\site-packages (from Keras) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in d:\\anaconda3\\lib\\site-packages (from Keras) (1.0.5)\n",
      "Requirement already satisfied: h5py in d:\\anaconda3\\lib\\site-packages (from Keras) (2.7.1)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda3\\lib\\site-packages (from Keras) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\anaconda3\\lib\\site-packages (from Keras) (1.14.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#warnings關掉\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#輸入datasets\n",
    "from sklearn import datasets\n",
    "#pandas可以提供高效能、簡易使用的資料格式(DataFrame)，讓使用者可以快速操作及分析資料\n",
    "import pandas as pd\n",
    "#數學公式計算都靠它\n",
    "import numpy as np\n",
    "#畫圖都靠它\n",
    "import matplotlib.pyplot as plt\n",
    "#此套件可將資料自由切分成 訓練資料集 和 測試資料集\n",
    "from sklearn.model_selection import train_test_split\n",
    "#標準化資料集\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "#DNN在Keras分類器演算法的套件\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "#計算accuracy,recall,precision測量指標\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、使用安德森鳶尾花卉數據集(Iris dataset)來做數據分析-資料前處理-雙類別\n",
    "Iris 資料集的介紹：http://bit.ly/2ptEM0N （連結到wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#輸入資料集\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris['data']是資料內容\n",
    "#數據標準化(normalization)主要解決不同性質數據問題，讓每一個性質的資料可以在同一個起跑點作分析\n",
    "#常見方法有:Max-Min scalar; z-score statistic scalar; maxabs scaler; robust scaler等\n",
    "#此處我將使用Max-Min scalar做示範\n",
    "x_iris = minmax_scale(iris['data'],feature_range=(0, 1), axis=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0           0.222222          0.625000           0.067797          0.041667\n",
       "1           0.166667          0.416667           0.067797          0.041667\n",
       "2           0.111111          0.500000           0.050847          0.041667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#存取成dataFrame形式:  iris['feature_names']是資料標題\n",
    "x_iris = pd.DataFrame(x_iris, columns=iris['feature_names'])\n",
    "#只要看到\".head()\"都是pandas呈現資料用\n",
    "x_iris.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#存取成dataFrame形式: iris['target']是類別\n",
    "y_iris = pd.DataFrame(iris['target'], columns=['target'])\n",
    "y_iris.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0           0.222222          0.625000           0.067797          0.041667   \n",
       "1           0.166667          0.416667           0.067797          0.041667   \n",
       "2           0.111111          0.500000           0.050847          0.041667   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將資料與類別合併在一起\n",
    "iris_data = pd.concat([x_iris,y_iris], axis=1)\n",
    "#因為原始的SVM是一個兩類別分類的問題，因此我們在此先取兩個類別作分類\n",
    "#（不過Sklearn其實也能做多類別分類的問題，所以看您分類的需求來做處理）\n",
    "iris_data = iris_data[iris_data['target'].isin([0,1])]\n",
    "iris_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將Iris資料隨機切分成 70%訓練資料集 和 30%測試資料集\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    iris_data[['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']], \n",
    "    iris_data[['target']], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、透過Keras來做DNN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#透過層數4-8-4-2-1來做DNN分類\n",
    "model = Sequential()\n",
    "start_unit = 8\n",
    "model.add(Dense(units=start_unit, input_dim=4,kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "for i in range(0,2):\n",
    "    start_unit = int(start_unit/2)\n",
    "    print(start_unit)\n",
    "    model.add(Dense(units=start_unit,kernel_initializer='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "model.add(Dense(units=1,kernel_initializer='uniform'))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN在Keras的compile\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63 samples, validate on 7 samples\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6932 - acc: 0.5397 - val_loss: 0.6932 - val_acc: 0.4286\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.6932 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.4286\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.6932 - acc: 0.5079 - val_loss: 0.6933 - val_acc: 0.4286\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6931 - acc: 0.5079 - val_loss: 0.6933 - val_acc: 0.4286\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.6931 - acc: 0.5079 - val_loss: 0.6933 - val_acc: 0.4286\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.6931 - acc: 0.5079 - val_loss: 0.6933 - val_acc: 0.4286\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6931 - acc: 0.5079 - val_loss: 0.6933 - val_acc: 0.4286\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.6931 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.4286\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6931 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.4286\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6930 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.4286\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 349us/step - loss: 0.6929 - acc: 0.5079 - val_loss: 0.6931 - val_acc: 0.4286\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.6928 - acc: 0.5079 - val_loss: 0.6930 - val_acc: 0.4286\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6926 - acc: 0.5079 - val_loss: 0.6927 - val_acc: 0.4286\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.6923 - acc: 0.5079 - val_loss: 0.6923 - val_acc: 0.4286\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.6919 - acc: 0.5714 - val_loss: 0.6919 - val_acc: 0.7143\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.6914 - acc: 0.9524 - val_loss: 0.6912 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6908 - acc: 1.0000 - val_loss: 0.6903 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.6899 - acc: 1.0000 - val_loss: 0.6892 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6888 - acc: 1.0000 - val_loss: 0.6879 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 317us/step - loss: 0.6875 - acc: 1.0000 - val_loss: 0.6864 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6860 - acc: 1.0000 - val_loss: 0.6845 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6841 - acc: 1.0000 - val_loss: 0.6821 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 333us/step - loss: 0.6820 - acc: 0.9841 - val_loss: 0.6793 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.6795 - acc: 0.9683 - val_loss: 0.6762 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6765 - acc: 0.9683 - val_loss: 0.6730 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6732 - acc: 0.9524 - val_loss: 0.6687 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 381us/step - loss: 0.6694 - acc: 0.9524 - val_loss: 0.6643 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6653 - acc: 0.9524 - val_loss: 0.6589 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.6602 - acc: 0.9365 - val_loss: 0.6533 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 364us/step - loss: 0.6550 - acc: 0.9365 - val_loss: 0.6469 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.6491 - acc: 0.9365 - val_loss: 0.6397 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.6426 - acc: 0.9365 - val_loss: 0.6319 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 650us/step - loss: 0.6354 - acc: 0.9365 - val_loss: 0.6237 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.6277 - acc: 0.9365 - val_loss: 0.6150 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.6200 - acc: 0.9206 - val_loss: 0.6054 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.6110 - acc: 0.9206 - val_loss: 0.5954 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.6022 - acc: 0.9206 - val_loss: 0.5849 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.5924 - acc: 0.9365 - val_loss: 0.5737 - val_acc: 0.8571\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 349us/step - loss: 0.5828 - acc: 0.9048 - val_loss: 0.5620 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.5726 - acc: 0.9206 - val_loss: 0.5505 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.5614 - acc: 0.9206 - val_loss: 0.5383 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.5508 - acc: 0.9048 - val_loss: 0.5260 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 317us/step - loss: 0.5400 - acc: 0.9206 - val_loss: 0.5134 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.5284 - acc: 0.9206 - val_loss: 0.5014 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 555us/step - loss: 0.5180 - acc: 0.9365 - val_loss: 0.4887 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.5065 - acc: 0.9206 - val_loss: 0.4763 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.4958 - acc: 0.9206 - val_loss: 0.4641 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.4851 - acc: 0.9206 - val_loss: 0.4522 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 301us/step - loss: 0.4748 - acc: 0.9206 - val_loss: 0.4407 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.4649 - acc: 0.9365 - val_loss: 0.4294 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.4550 - acc: 0.9365 - val_loss: 0.4188 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.4453 - acc: 0.9524 - val_loss: 0.4087 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 397us/step - loss: 0.4362 - acc: 0.9524 - val_loss: 0.3990 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.4278 - acc: 0.9524 - val_loss: 0.3893 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 383us/step - loss: 0.4193 - acc: 0.9524 - val_loss: 0.3799 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.4114 - acc: 0.9524 - val_loss: 0.3711 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 349us/step - loss: 0.4038 - acc: 0.9524 - val_loss: 0.3631 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 301us/step - loss: 0.3969 - acc: 0.9683 - val_loss: 0.3550 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 301us/step - loss: 0.3899 - acc: 0.9683 - val_loss: 0.3477 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.3836 - acc: 0.9683 - val_loss: 0.3408 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 286us/step - loss: 0.3776 - acc: 0.9683 - val_loss: 0.3356 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.3717 - acc: 0.9683 - val_loss: 0.3291 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 396us/step - loss: 0.3662 - acc: 0.9683 - val_loss: 0.3234 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.3611 - acc: 0.9683 - val_loss: 0.3166 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 333us/step - loss: 0.3562 - acc: 0.9683 - val_loss: 0.3118 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.3515 - acc: 0.9683 - val_loss: 0.3085 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 412us/step - loss: 0.3468 - acc: 0.9683 - val_loss: 0.3042 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.3424 - acc: 0.9841 - val_loss: 0.2999 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 349us/step - loss: 0.3383 - acc: 0.9841 - val_loss: 0.2951 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.3343 - acc: 0.9841 - val_loss: 0.2914 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.3303 - acc: 1.0000 - val_loss: 0.2873 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.3267 - acc: 0.9841 - val_loss: 0.2833 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.3232 - acc: 0.9841 - val_loss: 0.2795 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 380us/step - loss: 0.3198 - acc: 0.9841 - val_loss: 0.2765 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.3164 - acc: 1.0000 - val_loss: 0.2731 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.3133 - acc: 1.0000 - val_loss: 0.2702 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.3101 - acc: 1.0000 - val_loss: 0.2675 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.3071 - acc: 1.0000 - val_loss: 0.2649 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.3042 - acc: 1.0000 - val_loss: 0.2627 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 460us/step - loss: 0.3011 - acc: 1.0000 - val_loss: 0.2601 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 365us/step - loss: 0.2983 - acc: 1.0000 - val_loss: 0.2572 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 397us/step - loss: 0.2956 - acc: 1.0000 - val_loss: 0.2543 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.2929 - acc: 1.0000 - val_loss: 0.2518 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.2903 - acc: 1.0000 - val_loss: 0.2494 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.2878 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.2853 - acc: 1.0000 - val_loss: 0.2449 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.2829 - acc: 1.0000 - val_loss: 0.2426 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.2806 - acc: 1.0000 - val_loss: 0.2405 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 603us/step - loss: 0.2782 - acc: 1.0000 - val_loss: 0.2383 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 349us/step - loss: 0.2759 - acc: 1.0000 - val_loss: 0.2363 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 619us/step - loss: 0.2738 - acc: 1.0000 - val_loss: 0.2344 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 333us/step - loss: 0.2715 - acc: 1.0000 - val_loss: 0.2324 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 635us/step - loss: 0.2694 - acc: 1.0000 - val_loss: 0.2303 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 428us/step - loss: 0.2672 - acc: 1.0000 - val_loss: 0.2286 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 476us/step - loss: 0.2652 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2095 - acc: 1.000 - 0s 365us/step - loss: 0.2630 - acc: 1.0000 - val_loss: 0.2253 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 317us/step - loss: 0.2610 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.2591 - acc: 1.0000 - val_loss: 0.2219 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 381us/step - loss: 0.2570 - acc: 1.0000 - val_loss: 0.2201 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 444us/step - loss: 0.2550 - acc: 1.0000 - val_loss: 0.2185 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc45fe16d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DNN在Keras的運算\n",
    "model.fit(x=train_X, y =train_y,epochs=100,validation_split=0.1,batch_size=8,verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 67us/step\n",
      "[0.248725026845932, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#DNN在Keras的預測結果（loss, accuracy）\n",
    "scores = model.evaluate(x=test_X,y=test_y)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#DNN在Keras的預測結果（y_pred）\n",
    "\n",
    "preds = model.predict(test_X, verbose=1)\n",
    "y_pred = []\n",
    "for i in preds:\n",
    "    if i >= 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n",
      "Precision = 1.0\n",
      "Recall = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 0, 0, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score ,confusion_matrix\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "precision = precision_score(test_y, y_pred,pos_label=1)\n",
    "recall = recall_score(test_y, y_pred,pos_label=1)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, y_pred).ravel()\n",
    "\n",
    "print('Accuracy = ' + str(accuracy) +'\\nPrecision = ' + str(precision) +'\\nRecall = ' + str(recall))\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000        15\n",
      "          1     1.0000    1.0000    1.0000        15\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_pred,digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
